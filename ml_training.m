% Set Seed
seed = 314159;
rng( seed );

% Import table
data = readtable( ...
    'combat_features.csv', ...
    'readvariablenames', true ...
    );
predictor_variable_names = { ...
    'left_first_type', ...
    'left_second_type', ...
    'right_first_type', ...
    'right_second_type', ...
    'hp_diff', ...
    'attack_diff', ...
    'defense_diff', ...
    'spatk_diff', ...
    'spdef_diff', ...
    'speed_diff' ...
    };
predictors = data{ :, predictor_variable_names };
response = data{ :, { 'left_side_won' } };
classes = unique( response );
if numel( classes ) > 2
    one_hot_classes = bsxfun( @eq, response( : ), classes );
else
    one_hot_classes = bsxfun( @eq, response( : ), classes( 2 ) );
end
observation_count = size( data, 1 );


% Parameters
cross_validation_k_fold = 10;
tree_split_count = size( predictors, 1 ) - 1;
learning_cycle_count = 30;

% Bagged Trees (default)
template = templateTree( ...
    'MaxNumSplits', tree_split_count ...
    );
bagged_trees_model = fitcensemble( ...
    predictors, response, ...
    'method', 'bag', ...
    'numlearningcycles', learning_cycle_count, ...
    'learners', template, ...
    'predictornames', predictor_variable_names, ...
    'classnames', classes, ...
    );

trained_classifier.predict_fn = @(x) predict( bagged_trees_model, x );
trained_classifier.predictor_variable_names = predictor_variable_names;
trained_classifier.model = bagged_trees_model;

partitioned_model = crossval( ...
    trained_classifier.model, ...
    'kfold', cross_validation_k_fold ...
    );
[ val_predictions, val_scores ] = kfoldPredict( partitioned_model );
val_accuracy = 1 - kfoldLoss( partitioned_model, 'lossfun', 'classiferror' );

[ ~, ~, aucs, opt_thresh ] = plot_roc( classes, response, val_scores, get_colors() );
cm = confusionmat( response, val_predictions );
%plotConfMat( cm ); % swap to confusionmat on or after R2018b, delete plotConfMat


% Things to look into
% sequentialfs - automated feature selection
% relieff - same
%
% hyperparameter optimization
%
% repartition for monte carlo analysis of cross-validation